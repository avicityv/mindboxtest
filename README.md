Тестовое задание Mindbox на позицию SRE<br>
<br>
00:00 02.01<br>
Начало работу, пытался найти инфу о мультизональных кластерах, ничего внятного не нашёл. Понял, что это AWS, но с AWS я не работал, не знаю что делать на практике.<br>
Уже мысля что в LivenessProbe нужен кд секунд 11.<br>
<br>
0:40 
Уже написал Deployment, но теперь думаю что же делать с информацией про мультизональости. Впервые слышу об этом. <br>
Есть глупая идея реализовать изменение количества реплик через Job и CronJob, но мне кажется это кринж идея, и есть варианты поумнее, слышал про горизонтальное масштабирование, но не вчитывался. <br>
<br>
0:43 
Нашёл статейку по HPA, оказывается это то, что мне и нужно. https://habr.com/ru/companies/otus/articles/457742/<br>
Своровал оттуда HPA.yaml, попробую преобразовать его под то, что нужно в этом кейсе. <br>
<br>
0:52<br>
Загуглил доку кубика по теме, вчитался, покрутил лимиты чтобы примерно по циферкам выглядело адекватно, добавил MetricsServer.yaml, с которого и будут сыпаться метрики, о котором в статейке упомянуто вскольз и без подробностей. <br>
<br>
1:03<br>
Всё, горизонтальное масштабирование реализовано. Сейчас проведу ресёрч про мультизональность. <br>
<br>
Обратился за помощью к высшему интеллекту, выдал решение в spec : affinity, но оно не совсем удволетворяет условиям ТЗ.<br>
<br>
Ответ ИИ:<br>
 &emsp; &emsp; affinity:<br>
 &emsp; &emsp;podAntiAffinity:  # Обеспечиваем антипаттерн для отказоустойчивости<br>
 &emsp; &emsp; &emsp;requiredDuringSchedulingIgnoredDuringExecution:<br>
 &emsp; &emsp; &emsp;- labelSelector:<br>
 &emsp; &emsp; &emsp; &emsp;matchExpressions:<br>
 &emsp; &emsp; &emsp; &emsp; &emsp;- key: app<br>
 &emsp; &emsp; &emsp; &emsp; &emsp;operator: In<br>
 &emsp; &emsp; &emsp; &emsp; &emsp;values:<br>
 &emsp; &emsp; &emsp; &emsp; &emsp;- my-app<br>
 &emsp; &emsp; &emsp;&ensp;topologyKey: "failure-domain.beta.kubernetes.io/zone"  # Размещение по зонам<br>
▎Объяснение:<br>
 affinity: Используем podAntiAffinity, чтобы гарантировать, что поды не будут размещаться в одной и той же зоне. Это помогает обеспечить отказоустойчивость.<br>
 topologyKey: Указываем failure-domain.beta.kubernetes.io/zone, чтобы Kubernetes распределял поды по различным зонам.<br>
"<br>
<br>
Тут трабл в том, что у нас ТРИ зоны, и если мы укажем чтобы поды размещались в разных, 4й не встанет. Лезу в доку.<br>
В операторах в доке нашёл забавную штучку, оператор - DoesNotExist	No label with this key exists on the object <br>
Понял что тут задача в том, что нужно описать правила для Affinity/AntiAffinity с разным весом. Сначала проверка по тому, есть ли в зоне, потом проверка, есть ли на ноде. <br>
<br>
1:25 Пробую решить поставленную задачу. <br>
Решил <br>
